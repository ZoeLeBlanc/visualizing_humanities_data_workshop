{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf1cc55",
   "metadata": {},
   "source": [
    "## Day 2 Group and Homework Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3f23f",
   "metadata": {},
   "source": [
    "The goal of this notebook is to give you a chance to experiment with Altair and a variety of textual datasets. Your goal is to load in your selected dataset, and then based on the textual data make visualizations. While you can use additional metadata fields, at least one of your encoding channels needs to be representing data derived from text. \n",
    "\n",
    "In terms of how you derive that data, it is completely up to you! I imagine most will be doing word counts, but feel free to try out other methods.\n",
    "\n",
    "A great place to find relevant more advanced methods tutorials is Programming Historian https://programminghistorian.org/en/lessons/ but don't rush to try out fancier methods. The goal here is really to focus on how best to visualize your data.\n",
    "\n",
    "To that end, you'll need to make one good and one bad data visualization before we meet on Friday. What is bad or good data visualization? Pretty much up to you! You might decide to show the impact of color scales or maybe binning on distorting how a reader might interpret your graph. While there are some general rules of thumb, even things like data-ink-ratio may not be the ideal approach depending on your dataset. \n",
    "\n",
    "Given that visualizing data is an argument, I would highly recommend either starting to work with your own textual data or selecting one or two datasets that have data that really spark your interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be526b",
   "metadata": {},
   "source": [
    "Here's a list of available datasets in our binder instance but feel free to work with your own data as well!\n",
    "\n",
    "Available textual datasets:\n",
    "- Humanist Listserv `web_scraped_humanist_listserv.csv` web scraped from https://humanist.kdl.kcl.ac.uk/\n",
    "- NYT Obiturary data in `programm_historian_tfidf_txt_files` a directory of text files from Programming Historian Lesson on TFIDF https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf\n",
    "\n",
    "From Melanie's TAPI Pandas course https://github.com/melaniewalsh/Data-Analysis-with-Pandas\n",
    "- `Trump-Tweet-Topics.csv` from the https://www.thetrumparchive.com/\n",
    "\n",
    "From Raf's TAPI Topic Modeling course https://github.com/ontoligent/TAPI_Topic_Models\n",
    "- Wine Reviews `winereviews-tapi.csv` — A collection of terse wine reviews.\n",
    "- JSTOR Hyperparameter `jstor_hyperparameter-tapi.csv` — Abstracts from a JSTOR search for \"hyperparameter.\"\n",
    "- Tamilnet `tamilnet-tapi.csv` — A sample of news stories from the website Tamilnet.\n",
    "- Anphoblach `anphoblacht-tapi.csv` — A sample of news stories from the website Anphoblacht.\n",
    "\n",
    "I've also added the `htrc-feature-reader` to our binder instance so you could follow instructions in this Programming Historian tutorial to compile your own HathiTrust dataset https://programminghistorian.org/en/lessons/text-mining-with-extracted-features or you can try out the Constellate dataset builder option https://constellate.org/builder/ (you'll have to work either locally, in Google colab, or get me to upload the data to the Github repo for this one though).\n",
    "\n",
    "One cautionary note is that you don't want to get bogged down looking for the perfect dataset, so focus more on datasets where you feel like you have some inkling of what might be in the data since that will help you with the textual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fe605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz_hum_data_env",
   "language": "python",
   "name": "viz_hum_data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
